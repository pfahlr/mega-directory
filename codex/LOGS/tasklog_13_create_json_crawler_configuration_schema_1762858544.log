OpenAI Codex v0.57.0 (research preview)
--------
workdir: /var/home/rick/Development/mega-directory
model: gpt-5-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019a728e-afae-7bb2-bec6-67a13a1e69bf
--------
user
Implement the functionality described in codex/TASKS/13_create_json_crawler_configuration_schema.yaml, then verify with any available tests.

thinking
**Checking repository for instructions**
exec
bash -lc ls in /var/home/rick/Development/mega-directory succeeded in 39ms:
admin
agents
AGENTS.md
api
astro
codex
codex.toml
codex.yaml
db
docker-compose.yml
docs
README.md

thinking
**Opening task instructions file**
exec
bash -lc 'ls codex/TASKS' in /var/home/rick/Development/mega-directory succeeded in 38ms:
00_prepare_repository.yaml
01_initialize_astro_frontend.yaml
02_setup_api_server_with_express_and_jwt_auth.yaml
03_design_postgresql_schema.yaml
04_implement_listing_ingestion_api_endpoint.yaml
05_admin_auth_route_and_middleware.yaml
06_frontend_directory_page_rendering.yaml
07_frontend_subcategory_ui_and_layout.yaml
08_setup_featured_listings_logic.yaml
09_add_category_meta_and_seo_controls.yaml
10_scaffold_python_crawler_agent.yaml
11_llm_field_generation_via_jinja2.yaml
12_post_listings_from_crawler_to_api_server.yaml
13_create_json_crawler_configuration_schema.yaml
14_scaffold_admin_ui_application.yaml
15_admin_ui:_listing_review_table.yaml
16_admin_ui:_category_location_approval.yaml
17_admin_ui:_seo_field_editor.yaml
18_deploy_web_+_api_to_railway.yaml
19_setup_logging,_healthchecks_and_monitoring.yaml

thinking
**Preparing to implement functionality**
exec
bash -lc 'cat codex/TASKS/13_create_json_crawler_configuration_schema.yaml' in /var/home/rick/Development/mega-directory succeeded in 38ms:
id: 13
title: Create JSON Crawler Configuration Schema
description: Define JSON schema for specifying category, location, keywords, and per-field
  LLM config.
dependencies:
- 10

thinking
**Searching for crawler config details**
exec
bash -lc 'rg -n "crawler" -n "configuration" -g"*.md"' in /var/home/rick/Development/mega-directory exited 2 in 40ms:
rg: configuration: IO error for operation on configuration: No such file or directory (os error 2)

thinking
**Correcting ripgrep command usage**
exec
bash -lc 'rg -n "crawler"' in /var/home/rick/Development/mega-directory succeeded in 61ms:
AGENTS.md:77:Serve listings to the frontend, receive data from crawler, and power the admin interface.
AGENTS.md:88:* Accept and validate new data from the crawler
codex.yaml:24:    path: codex/TASKS/10_scaffold_python_crawler_agent.yaml
codex.yaml:28:    path: codex/TASKS/12_post_listings_from_crawler_to_api_server.yaml
codex.yaml:30:    path: codex/TASKS/13_create_json_crawler_configuration_schema.yaml
docs/AGENTS.md:77:Serve listings to the frontend, receive data from crawler, and power the admin interface.
docs/AGENTS.md:88:* Accept and validate new data from the crawler
api/test/server.test.js:12:  crawlerBearerToken: 'crawler-token'
api/test/server.test.js:197:test('crawler ping rejects invalid bearer token', () => {
api/test/server.test.js:199:  const route = findRoute(app, 'post', '/v1/crawler/ping');
api/test/server.test.js:210:test('crawler ping accepts matching bearer token', () => {
api/test/server.test.js:212:  const route = findRoute(app, 'post', '/v1/crawler/ping');
api/test/server.test.js:215:    headers: { Authorization: `Bearer ${baseConfig.crawlerBearerToken}` }
api/test/server.test.js:220:  assert.deepStrictEqual(res.body, { status: 'crawler-ok' });
api/test/server.test.js:223:test('crawler listing ingestion rejects missing bearer token', () => {
api/test/server.test.js:225:  const route = findRoute(app, 'post', '/v1/crawler/listings');
api/test/server.test.js:236:test('crawler listing ingestion stores sanitized listings as inactive', () => {
api/test/server.test.js:238:  const route = findRoute(app, 'post', '/v1/crawler/listings');
api/test/server.test.js:241:    headers: { Authorization: `Bearer ${baseConfig.crawlerBearerToken}` },
api/test/server.test.js:264:test('crawler listing ingestion accepts batches and reports metadata', () => {

thinking
**Preparing to locate target file path**
exec
bash -lc "sed -n '1,160p' README.md" in /var/home/rick/Development/mega-directory succeeded in 42ms:
# Mega Directory

Mega Directory is a server-rendered directory listing platform built with Astro, Express, and Prisma. It supports dynamic subdomains, AI-generated content enrichment, and moderation workflows.

## Features

- ðŸ›°ï¸ Subdomain-based regional directories (e.g. electricians.nyc.example.com)
- âš¡ Express API with JWT-based auth
- ðŸ§  AI agents for crawling, enrichment, and moderation (via OpenRouter)
- ðŸ§© Admin dashboard for approving or rejecting listings
- ðŸ’… Tailwind CSS and minimal JavaScript for accessibility and performance
- ðŸ³ Dockerized and deployable behind Cloudflare with SSR

## Tech Stack

- Astro (SSR)
- Express.js
- Prisma + PostgreSQL
- Tailwind CSS
- OpenRouter (AI Agents)

thinking
**Exploring crawler config schema**
exec
bash -lc 'ls agents/crawler' in /var/home/rick/Development/mega-directory succeeded in 38ms:
config
crawler.py
main.py
__pycache__
targets.example.json
tests

thinking
**Checking for config directory**
exec
bash -lc 'ls agents/crawler/config' in /var/home/rick/Development/mega-directory succeeded in 40ms:
targets.json

thinking
**Checking configuration file**
exec
bash -lc 'cat agents/crawler/targets.example.json' in /var/home/rick/Development/mega-directory succeeded in 38ms:
{
  "api_targets": [
    {
      "name": "dev",
      "endpoint": "http://localhost:3001/v1/crawler/listings",
      "token": "dev-token"
    },
    {
      "name": "prod",
      "endpoint": "https://api.yourdomain.com/v1/crawler/listings",
      "token": "prod-token"
    }
  ],
  "targets": [
    {
      "category": "Real Estate",
      "locations": ["New York", "San Francisco"],
      "subdomain": "realestate.local",
      "keywords": ["ocean view", "downtown"],
      "listings_per_location": 50,

thinking
**Opening configuration file**
exec
bash -lc 'cat agents/crawler/config/targets.json' in /var/home/rick/Development/mega-directory succeeded in 49ms:
{
  "api_targets": [
    {
      "name": "dev",
      "endpoint": "http://localhost:3001/v1/crawler/listings",
      "token": "YOUR_DEV_API_TOKEN"
    },
    {
      "name": "prod",
      "endpoint": "https://api.example.com/v1/crawler/listings",
      "token": "YOUR_PROD_API_TOKEN"
    }
  ],
  "targets": [
    {
      "category": "Electricians",
      "locations": [
        "Holland MI"
      ],
      "subdomain": "electricians.example.com",

thinking
**Checking crawler.py for JSON schema**
exec
bash -lc "sed -n '1,200p' agents/crawler/crawler.py" in /var/home/rick/Development/mega-directory succeeded in 38ms:
from __future__ import annotations

from dataclasses import dataclass, field
import re
from typing import Any, Callable, Dict, Iterable, List, Optional
from urllib.parse import quote_plus, urljoin

import requests
from bs4 import BeautifulSoup
from jinja2 import Environment, StrictUndefined, TemplateError

try:
    import requests_cache
except ModuleNotFoundError:  # pragma: no cover - shim is only needed locally
    from types import SimpleNamespace

    class _ShimCachedSession(requests.Session):
        """Minimal drop-in replacement when requests-cache is unavailable."""

        def __init__(self, *args, **kwargs):

thinking
**Continuing schema reference checks**
exec
bash -lc "sed -n '200,400p' agents/crawler/crawler.py" in /var/home/rick/Development/mega-directory succeeded in 38ms:
        prompt_template = config.get("prompt_template")
        if not provider or not model or not prompt_template:
            raise ValueError(
                f"AI field '{field_name}' requires provider, model, and prompt_template"
            )

        render_context = self._prepare_render_context(context, config)
        prompt = self._render_template(field_name, prompt_template, render_context)
        request = LLMRequest(
            provider=provider,
            model=model,
            prompt=prompt,
            field_name=field_name,
            options=config.get("options", {}),
            target=target,
            listing=context.get("listing"),
        )
        return self.llm_client(request)

    def _prepare_render_context(

thinking
**Proceeding with next steps**
exec
bash -lc "sed -n '400,800p' agents/crawler/crawler.py" in /var/home/rick/Development/mega-directory succeeded in 49ms:
            url = f"https:{url}"
        if not url.startswith("http"):
            url = f"https://{url.lstrip('/')}"
        return url

    @staticmethod
    def _normalize_subdomain(value: Optional[str]) -> str:
        if not value:
            return ""
        if value.startswith("http://") or value.startswith("https://"):
            return value.rstrip("/")
        return f"https://{value.strip('/')}"

    @staticmethod
    def _normalize_url(
        href: str,
        subdomain: Optional[str],
    ) -> str:
        if not href:
            return ""

thinking
**Checking config usage location**
exec
bash -lc "sed -n '1,200p' agents/crawler/main.py" in /var/home/rick/Development/mega-directory succeeded in 42ms:
import json
from crawler import run_crawler

if __name__ == "__main__":
    with open("config/targets.json", "r") as f:
        config = json.load(f)
    run_crawler(config)

thinking
**Checking for existing tests**
exec
bash -lc 'ls agents/crawler/tests' in /var/home/rick/Development/mega-directory succeeded in 49ms:
__pycache__
test_crawler.py
exec
bash -lc "sed -n '1,200p' agents/crawler/tests/test_crawler.py" in /var/home/rick/Development/mega-directory succeeded in 54ms:
from pathlib import Path
from types import SimpleNamespace
import sys

import pytest

AGENT_DIR = Path(__file__).resolve().parents[1]
if str(AGENT_DIR) not in sys.path:
    sys.path.insert(0, str(AGENT_DIR))

import crawler
from crawler import run_crawler


SAMPLE_HTML = """
<section>
  <article data-listing>
    <a class="listing-link" href="https://example.com/acme">
      <span class="listing-title">ACME Electric</span>
    </a>

thinking
**Considering adding schema tests**
exec
bash -lc "sed -n '200,400p' agents/crawler/tests/test_crawler.py" in /var/home/rick/Development/mega-directory succeeded in 49ms:

def test_run_crawler_errors_if_ai_field_without_llm_client() -> None:
    config = {
        "api_endpoint": "https://api.example.com",
        "api_token": "token",
        "targets": [
            {
                "category": "Electricians",
                "locations": ["Holland MI"],
                "fields": {
                    "description": {
                        "source": "ai",
                        "provider": "openai",
                        "model": "gpt-4",
                        "prompt_template": "Describe {{ listing.title }}",
                    }
                },
            }
        ],
    }

thinking
**Planning JSON schema creation**
exec
bash -lc 'cat codex/TASKS/10_scaffold_python_crawler_agent.yaml' in /var/home/rick/Development/mega-directory succeeded in 58ms:
id: 10
title: Scaffold Python Crawler Agent
description: Build Python module using requests, BeautifulSoup4, and requests-cache.
  Read from config and support category-location batches.
dependencies: []

thinking
**Starting task 11**
exec
bash -lc 'cat codex/TASKS/11_llm_field_generation_via_jinja2.yaml' in /var/home/rick/Development/mega-directory succeeded in 57ms:
id: 11
title: LLM Field Generation via Jinja2
description: Add dynamic field generation with provider/model config, jinja2 templates,
  and token substitution.
dependencies:
- 10

thinking
**Identifying next task**
exec
bash -lc 'cat codex/TASKS/12_post_listings_from_crawler_to_api_server.yaml' in /var/home/rick/Development/mega-directory succeeded in 53ms:
id: 12
title: POST Listings from Crawler to API Server
description: After field population, push data to API using HTTP and token. Validate
  integration against dev and prod targets.
dependencies:
- 4
- 10

thinking
**Planning JSON crawler schema creation**
exec
bash -lc 'rg -n "schema"' in /var/home/rick/Development/mega-directory succeeded in 66ms:
codex.yaml:10:    path: codex/TASKS/03_design_postgresql_schema.yaml
codex.yaml:30:    path: codex/TASKS/13_create_json_crawler_configuration_schema.yaml
astro/package-lock.json:1908:        "zod-to-json-schema": "^3.24.6",
astro/package-lock.json:6354:    "node_modules/zod-to-json-schema": {
astro/package-lock.json:6356:      "resolved": "https://registry.npmjs.org/zod-to-json-schema/-/zod-to-json-schema-3.24.6.tgz",
db/migrations/001_core_schema.sql:1:-- Core relational schema for Mega Directory
README.md:34:Database schema and seed scripts live under `/db`. Run Prisma commands from the `api` workspace once the API server has been configured with a connection string (see future Codex tasks for details).
README.md:71:/db                - Prisma schema and seeding scripts
codex/TASKS/work_list:11:13_create_json_crawler_configuration_schema.yaml
codex/TASKS/13_create_json_crawler_configuration_schema.yaml:3:description: Define JSON schema for specifying category, location, keywords, and per-field
codex/TASKS/CODEX_TODO.md:18:- [ ] 03_initialize_database_schema.yaml â€” Define and migrate core tables: listings, categories, locations, directory.
codex/LOGS/codex_run_2025-11-11_03-24-35.log:7:Tasks: 01_initialize_astro_frontend 02_initialize_api_server 03_initialize_database_schema 04_initialize_admin_app 05_initialize_python_crawler 23_docker_compose_local_dev 06_api_endpoints_listings 07_api_endpoints_categories 08_api_token_auth
codex/LOGS/tasklog_23_docker_compose_local_dev_1762853831.log:209:schema.prisma
codex/LOGS/tasklog_23_docker_compose_local_dev_1762853831.log:351:codex/LOGS/tasklog_05_admin_auth_route_and_middleware_1762853548.log:306:codex/LOGS/tasklog_03_design_postgresql_schema_1762852701.log:269:    adminJwtSecret: overrides.adminJwtSecret ?? process.env.ADMIN_JWT_SECRET,
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:13:Implement the functionality described in codex/TASKS/13_create_json_crawler_configuration_schema.yaml, then verify with any available tests.
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:39:03_design_postgresql_schema.yaml
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:49:13_create_json_crawler_configuration_schema.yaml
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:60:bash -lc 'cat codex/TASKS/13_create_json_crawler_configuration_schema.yaml' in /var/home/rick/Development/mega-directory succeeded in 38ms:
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:63:description: Define JSON schema for specifying category, location, keywords, and per-field
codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log:82:codex.yaml:30:    path: codex/TASKS/13_create_json_crawler_configuration_schema.yaml

thinking
**Drafting JSON schema plan**

Iâ€™m mapping out the steps to create a JSON schema for the crawler config that covers category, location, keywords, and per-field LLM settings. I want to check existing tests and dependencies to see how to validate the schema against example configs and whether integration with the agent is needed. This task looks more involved than simple, so Iâ€™ll use a multi-step plan.
exec
bash -lc 'ls agents/crawler' in /var/home/rick/Development/mega-directory succeeded in 67ms:
config
crawler.py
main.py
__pycache__
targets.example.json
tests

thinking
**Checking for Python requirements and config files**
exec
bash -lc 'ls -a agents/crawler' in /var/home/rick/Development/mega-directory succeeded in 72ms:
.
..
config
crawler.py
main.py
__pycache__
targets.example.json
tests

thinking
**Considering JSON schema implementation approach**
exec
bash -lc 'find agents -maxdepth 2 -name "*requirements*" -o -name "pyproject.toml" -o -name "setup.cfg"' in /var/home/rick/Development/mega-directory succeeded in 101ms:


thinking
**Evaluating JSON schema approach**
exec
bash -lc "sed -n '1,200p' codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log" in /var/home/rick/Development/mega-directory succeeded in 54ms:
OpenAI Codex v0.57.0 (research preview)
--------
workdir: /var/home/rick/Development/mega-directory
model: gpt-5-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019a728e-afae-7bb2-bec6-67a13a1e69bf
--------
user
Implement the functionality described in codex/TASKS/13_create_json_crawler_configuration_schema.yaml, then verify with any available tests.

thinking
**Checking repository for instructions**
exec
bash -lc ls in /var/home/rick/Development/mega-directory succeeded in 39ms:
admin
agents

thinking
**Designing JSON schema and testing strategy**

Iâ€™m mapping out a detailed plan to create a JSON schema that accurately reflects the crawler config structure, including nested per-field LLM settings and optional keys. I want to write tests first to validate the schema and example configs, ideally using the `jsonschema` Python library if available, or else considering a minimal fallback. Iâ€™m also figuring out the best location for the schema file and how to update docs and tests accordingly. Letâ€™s see if the environment supports `jsonschema` to decide the approach.
exec
bash -lc 'python -c "import jsonschema"' in /var/home/rick/Development/mega-directory exited 124 in 1.00s:


thinking
**Verifying Python availability**
exec
bash -lc "python -c \"print('hi')\"" in /var/home/rick/Development/mega-directory succeeded in 77ms:
hi

thinking
**Adjusting timeout due to heavy import**
exec
bash -lc 'python -c "import jsonschema"' in /var/home/rick/Development/mega-directory succeeded in 641ms:


thinking
**Planning schema validation integration**
Plan update
  â†’ Create failing tests covering valid + invalid crawler configs via JSON schema validation.
  â€¢ Define JSON Schema file capturing API target + per-target fields and ensure example config references it.
  â€¢ Implement minimal validation helper or test harness updates and run pytest to verify.

thinking
**Drafting schema validation tests**
exec
bash -lc 'git status -sb' in /var/home/rick/Development/mega-directory succeeded in 103ms:
## main...origin/main [ahead 4]
 M codex/LOGS/codex_run_2025-11-11_04-26-54.log
 M codex/LOGS/tasklog_08_setup_featured_listings_logic_1762855542.log
?? agents/crawler/tests/
?? astro/src/components/DirectoryListing.astro
?? astro/src/components/DirectoryPage.astro
?? astro/src/data/
?? astro/src/lib/
?? astro/src/pages/listings/
?? astro/test/
?? codex/LOGS/tasklog_08_setup_featured_listings_logic_1762855542.log.done
?? codex/LOGS/tasklog_09_add_category_meta_and_seo_controls_1762856433.log
?? codex/LOGS/tasklog_09_add_category_meta_and_seo_controls_1762856433.log.done
?? codex/LOGS/tasklog_10_scaffold_python_crawler_agent_1762856938.log
?? codex/LOGS/tasklog_10_scaffold_python_crawler_agent_1762856938.log.done
?? codex/LOGS/tasklog_11_llm_field_generation_via_jinja2_1762857329.log
?? codex/LOGS/tasklog_11_llm_field_generation_via_jinja2_1762857329.log.done
?? codex/LOGS/tasklog_12_post_listings_from_crawler_to_api_server_1762857915.log
?? codex/LOGS/tasklog_12_post_listings_from_crawler_to_api_server_1762857915.log.done
?? codex/LOGS/tasklog_13_create_json_crawler_configuration_schema_1762858544.log

thinking
**Preparing test file for JSON schema validation**
file update
A /var/home/rick/Development/mega-directory/agents/crawler/tests/test_config_schema.py
from __future__ import annotations

import json
from pathlib import Path

import jsonschema
import pytest


AGENT_DIR = Path(__file__).resolve().parents[1]
SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
EXAMPLE_PATH = AGENT_DIR / "targets.example.json"


@pytest.fixture(scope="module")
def schema() -> dict:
    """Load the crawler configuration schema once per test module."""
    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
        return json.load(fp)


def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
    validator = jsonschema.Draft202012Validator(schema)
    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))


def test_example_config_matches_schema(schema: dict) -> None:
    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
        config = json.load(fp)

    errors = _collect_errors(schema, config)

    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"


def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
    invalid_config = {
        "api_targets": [
            {
                "name": "dev",
                "endpoint": "https://dev.example.com/v1/crawler/listings",
                "token": "token",
            }
        ],
        "targets": [
            {
                # Missing category and locations entries to trigger schema errors
                "fields": {
                    "description": {
                        "source": "ai",
                        "model": "gpt-4",
                        "prompt_template": "Describe {{ listing.title }}",
                    }
                },
            }
        ],
    }

    errors = _collect_errors(schema, invalid_config)

    messages = "\n".join(error.message for error in errors)
    assert errors, "expected schema to flag invalid target configuration"
    assert "'category'" in messages
    assert "'locations'" in messages or "minItems" in messages
    assert "'provider'" in messages
apply_patch(auto_approved=true) exited 0 in 5ms:
Success. Updated the following files:
A agents/crawler/tests/test_config_schema.py
file update:
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

file update:
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Running tests to confirm failure**
exec
bash -lc 'cd agents/crawler && pytest tests/test_config_schema.py' in /var/home/rick/Development/mega-directory exited 1 in 1.99s:
============================= test session starts ==============================
platform linux -- Python 3.13.7, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/mega-directory/agents/crawler
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 2 items

tests/test_config_schema.py EE                                           [100%]

==================================== ERRORS ====================================
_____________ ERROR at setup of test_example_config_matches_schema _____________

    @pytest.fixture(scope="module")
    def schema() -> dict:
        """Load the crawler configuration schema once per test module."""
>       with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_config_schema.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
file update:
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Designing detailed JSON schema file**

I'm mapping out a comprehensive JSON schema for crawler targets, carefully structuring properties, required fields, and flexible allowances for future extensions. I'll define nested objects like `fieldConfig` with conditional requirements and ensure proper referencing and typing throughout to keep this schema robust and extensible.
file update
A /var/home/rick/Development/mega-directory/agents/crawler/config/targets.schema.json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
  "title": "Mega Directory Crawler Configuration",
  "type": "object",
  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
  "additionalProperties": true,
  "properties": {
    "$schema": {
      "type": "string",
      "description": "Optional pointer for tooling to locate this schema definition."
    },
    "api_endpoint": {
      "type": "string",
      "format": "uri",
      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
    },
    "api_token": {
      "$ref": "#/$defs/nonEmptyString",
      "description": "Bearer token paired with api_endpoint."
    },
    "api_request_timeout": {
      "$ref": "#/$defs/positiveNumber",
      "description": "Override timeout (seconds) when posting batches to the API."
    },
    "request_timeout": {
      "$ref": "#/$defs/positiveNumber",
      "description": "Override timeout (seconds) for crawling requests."
    },
    "api_targets": {
      "type": "array",
      "minItems": 1,
      "items": {
        "$ref": "#/$defs/apiTarget"
      },
      "description": "Optional list of named API targets (e.g., dev and prod)."
    },
    "targets": {
      "type": "array",
      "minItems": 1,
      "items": {
        "$ref": "#/$defs/target"
      },
      "description": "Collection of category/location scraping targets."
    }
  },
  "required": ["targets"],
  "allOf": [
    {
      "anyOf": [
        { "required": ["api_targets"] },
        { "required": ["api_endpoint", "api_token"] }
      ]
    }
  ],
  "$defs": {
    "nonEmptyString": {
      "type": "string",
      "minLength": 1
    },
    "positiveInteger": {
      "type": "integer",
      "minimum": 1
    },
    "positiveNumber": {
      "type": "number",
      "exclusiveMinimum": 0
    },
    "stringList": {
      "type": "array",
      "items": {
        "$ref": "#/$defs/nonEmptyString"
      },
      "minItems": 1
    },
    "apiTarget": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "name": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "endpoint": {
          "type": "string",
          "format": "uri"
        },
        "token": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "timeout": {
          "$ref": "#/$defs/positiveNumber"
        }
      },
      "required": ["endpoint", "token"]
    },
    "target": {
      "type": "object",
      "additionalProperties": true,
      "properties": {
        "category": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "category_slug": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "categorySlug": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "locations": {
          "$ref": "#/$defs/stringList"
        },
        "keywords": {
          "$ref": "#/$defs/stringList"
        },
        "subdomain": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "search_url_template": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "selectors": {
          "$ref": "#/$defs/selectors"
        },
        "fields": {
          "$ref": "#/$defs/fieldMap"
        },
        "listings_per_location": {
          "$ref": "#/$defs/positiveInteger"
        },
        "request_timeout": {
          "$ref": "#/$defs/positiveNumber"
        },
        "api_request_timeout": {
          "$ref": "#/$defs/positiveNumber"
        },
        "source_name": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "sourceName": {
          "$ref": "#/$defs/nonEmptyString"
        }
      },
      "required": ["category", "locations"]
    },
    "selectors": {
      "type": "object",
      "additionalProperties": true,
      "properties": {
        "listing": { "$ref": "#/$defs/nonEmptyString" },
        "title": { "$ref": "#/$defs/nonEmptyString" },
        "link": { "$ref": "#/$defs/nonEmptyString" },
        "description": { "$ref": "#/$defs/nonEmptyString" }
      }
    },
    "fieldMap": {
      "type": "object",
      "minProperties": 1,
      "patternProperties": {
        ".+": {
          "$ref": "#/$defs/fieldConfig"
        }
      }
    },
    "fieldConfig": {
      "type": "object",
      "additionalProperties": true,
      "properties": {
        "source": {
          "type": "string",
          "enum": ["scrape", "ai"],
          "default": "scrape"
        },
        "attribute": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "provider": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "model": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "prompt_template": {
          "$ref": "#/$defs/nonEmptyString"
        },
        "options": {
          "type": "object"
        },
        "tokens": {
          "type": "object",
          "additionalProperties": {
            "type": "string"
          }
        }
      },
      "allOf": [
        {
          "if": {
            "properties": {
              "source": { "const": "ai" }
            }
          },
          "then": {
            "required": ["provider", "model", "prompt_template"]
          }
        }
      ]
    }
  }
}
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
A agents/crawler/config/targets.schema.json
file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..67a04c7f1f49be0e8705fc7073f5648b77863ede
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,209 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint", "token"]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..67a04c7f1f49be0e8705fc7073f5648b77863ede
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,209 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint", "token"]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Refining schema for flexibility**

I'm updating the schema to allow synonyms for token properties like `api_token` and `bearer_token`, ensuring at least one is provided for `apiTarget`. I'm also confirming optional and required fields across configsâ€”like making `fields` optional but enforcing `minProperties` when presentâ€”and deciding against aliasing `prompt_template` to avoid confusion. This will better align the schema with the actual usage and fallback behavior in the code.
file update
M /var/home/rick/Development/mega-directory/agents/crawler/config/targets.schema.json
@@ -89,2 +89,8 @@
         },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
         "timeout": {
@@ -93,3 +99,12 @@
       },
-      "required": ["endpoint", "token"]
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
     },
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M agents/crawler/config/targets.schema.json
file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Updating config schema references**
file update
M /var/home/rick/Development/mega-directory/agents/crawler/targets.example.json
@@ -1,2 +1,3 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
M agents/crawler/targets.example.json
file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

file update:
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Updating JSON schema reference**
file update
M /var/home/rick/Development/mega-directory/agents/crawler/config/targets.json
@@ -1,2 +1,3 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
apply_patch(auto_approved=true) exited 0 in 12ms:
Success. Updated the following files:
M agents/crawler/config/targets.json
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Verifying schema and updating plan status**
Plan update
  âœ“ Create failing tests covering valid + invalid crawler configs via JSON schema validation.
  âœ“ Define JSON Schema file capturing API target + per-target fields and ensure example config references it.
  â†’ Implement minimal validation helper or test harness updates and run pytest to verify.
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Running tests for verification**
exec
bash -lc 'cd agents/crawler && pytest' in /var/home/rick/Development/mega-directory succeeded in 1.75s:
============================= test session starts ==============================
platform linux -- Python 3.13.7, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/mega-directory/agents/crawler
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 9 items

tests/test_config_schema.py ..                                           [ 22%]
tests/test_crawler.py .......                                            [100%]

============================== 9 passed in 0.91s ===============================
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Updating plan status**
Plan update
  âœ“ Create failing tests covering valid + invalid crawler configs via JSON schema validation.
  âœ“ Define JSON Schema file capturing API target + per-target fields and ensure example config references it.
  âœ“ Implement minimal validation helper or test harness updates and run pytest to verify.
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Preparing detailed file references**
exec
bash -lc 'git status -sb' in /var/home/rick/Development/mega-directory succeeded in 295ms:
## main...origin/main [ahead 4]
 M agents/crawler/config/targets.json
 M agents/crawler/targets.example.json
 M codex/LOGS/codex_run_2025-11-11_04-26-54.log
 M codex/LOGS/tasklog_08_setup_featured_listings_logic_1762855542.log
?? agents/crawler/config/targets.schema.json
?? agents/crawler/tests/
?? astro/src/components/DirectoryListing.astro
?? astro/src/components/DirectoryPage.astro
?? astro/src/data/
?? astro/src/lib/
?? astro/src/pages/listings/
?? astro/test/
?? codex/LOGS/tasklog_08_setup_featured_listings_logic_1762855542.log.done
?? codex/LOGS/tasklog_09_add_category_meta_and_seo_controls_1762856433.log
?? codex/LOGS/tasklog_09_add_category_meta_and_seo_controls_1762856433.log.done
?? codex/LOGS/tasklog_10_scaffold_python_crawler_agent_1762856938.log
?? codex/LOGS/tasklog_10_scaffold_python_crawler_agent_1762856938.log.done
?? codex/LOGS/tasklog_11_llm_field_generation_via_jinja2_1762857329.log
?? codex/LOGS/tasklog_11_llm_field_generation_via_jinja2_1762857329.log.done
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Preparing line number references for changes**
exec
bash -lc 'nl -ba agents/crawler/config/targets.schema.json | head -n 80' in /var/home/rick/Development/mega-directory succeeded in 39ms:
     1	{
     2	  "$schema": "https://json-schema.org/draft/2020-12/schema",
     3	  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
     4	  "title": "Mega Directory Crawler Configuration",
     5	  "type": "object",
     6	  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
     7	  "additionalProperties": true,
     8	  "properties": {
     9	    "$schema": {
    10	      "type": "string",
    11	      "description": "Optional pointer for tooling to locate this schema definition."
    12	    },
    13	    "api_endpoint": {
    14	      "type": "string",
    15	      "format": "uri",
    16	      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
    17	    },
    18	    "api_token": {
    19	      "$ref": "#/$defs/nonEmptyString",
    20	      "description": "Bearer token paired with api_endpoint."
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Continuing to review apiTarget updates**
exec
bash -lc "nl -ba agents/crawler/config/targets.schema.json | sed -n '76,200p'" in /var/home/rick/Development/mega-directory succeeded in 47ms:
    76	    "apiTarget": {
    77	      "type": "object",
    78	      "additionalProperties": false,
    79	      "properties": {
    80	        "name": {
    81	          "$ref": "#/$defs/nonEmptyString"
    82	        },
    83	        "endpoint": {
    84	          "type": "string",
    85	          "format": "uri"
    86	        },
    87	        "token": {
    88	          "$ref": "#/$defs/nonEmptyString"
    89	        },
    90	        "api_token": {
    91	          "$ref": "#/$defs/nonEmptyString"
    92	        },
    93	        "bearer_token": {
    94	          "$ref": "#/$defs/nonEmptyString"
    95	        },
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Pausing to gather more input**
exec
bash -lc "nl -ba agents/crawler/config/targets.schema.json | sed -n '200,320p'" in /var/home/rick/Development/mega-directory succeeded in 39ms:
   200	        "options": {
   201	          "type": "object"
   202	        },
   203	        "tokens": {
   204	          "type": "object",
   205	          "additionalProperties": {
   206	            "type": "string"
   207	          }
   208	        }
   209	      },
   210	      "allOf": [
   211	        {
   212	          "if": {
   213	            "properties": {
   214	              "source": { "const": "ai" }
   215	            }
   216	          },
   217	          "then": {
   218	            "required": ["provider", "model", "prompt_template"]
   219	          }
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Noting config file line numbers**
exec
bash -lc 'nl -ba agents/crawler/config/targets.json | head -n 10' in /var/home/rick/Development/mega-directory succeeded in 39ms:
     1	{
     2	  "$schema": "./targets.schema.json",
     3	  "api_targets": [
     4	    {
     5	      "name": "dev",
     6	      "endpoint": "http://localhost:3001/v1/crawler/listings",
     7	      "token": "YOUR_DEV_API_TOKEN"
     8	    },
     9	    {
    10	      "name": "prod",
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Previewing example file snippet**
exec
bash -lc 'nl -ba agents/crawler/targets.example.json | head -n 10' in /var/home/rick/Development/mega-directory succeeded in 41ms:
     1	{
     2	  "$schema": "./config/targets.schema.json",
     3	  "api_targets": [
     4	    {
     5	      "name": "dev",
     6	      "endpoint": "http://localhost:3001/v1/crawler/listings",
     7	      "token": "dev-token"
     8	    },
     9	    {
    10	      "name": "prod",
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Adding line numbers to test file**
exec
bash -lc 'nl -ba agents/crawler/tests/test_config_schema.py' in /var/home/rick/Development/mega-directory succeeded in 39ms:
     1	from __future__ import annotations
     2	
     3	import json
     4	from pathlib import Path
     5	
     6	import jsonschema
     7	import pytest
     8	
     9	
    10	AGENT_DIR = Path(__file__).resolve().parents[1]
    11	SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
    12	EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
    13	
    14	
    15	@pytest.fixture(scope="module")
    16	def schema() -> dict:
    17	    """Load the crawler configuration schema once per test module."""
    18	    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
    19	        return json.load(fp)
    20	
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages


thinking
**Composing final update summary with tests and suggestions**

I'll summarize the schema additions with file references, note the pytest command run, and suggest possible next steps like integrating runtime schema validation, keeping everything clear and helpful for the user.
codex
**Updates**
- Added a comprehensive JSON Schema that captures crawler-level API settings, per-target selectors, keyword lists, and conditional AI field requirements so configs can be validated consistently (agents/crawler/config/targets.schema.json:1).
- Linked both the example and active crawler configurations to the new schema via `$schema` pointers, enabling editor tooling and keeping the files self-describing (agents/crawler/targets.example.json:2, agents/crawler/config/targets.json:2).
- Introduced Pytest coverage to load the schema, ensure the example config passes, and confirm that malformed targets (missing category/locations or AI parameters) are rejected, giving us a regression harness for future schema tweaks (agents/crawler/tests/test_config_schema.py:1).

**Tests**
- `cd agents/crawler && pytest`

**Next**
1. Consider calling the schema validator before running the crawler so invalid configs are caught with a clear error message instead of failing mid-run.
file update:
diff --git a/agents/crawler/config/targets.json b/agents/crawler/config/targets.json
index 5553670f589b19a367f05be0225034a900f3301a..66bb20cdfeac1b20b808809bab8b535cc7b99654
--- a/agents/crawler/config/targets.json
+++ b/agents/crawler/config/targets.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/config/targets.schema.json b/agents/crawler/config/targets.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..2b86ce9670cdf8e9c84ea5e81f08b41704c01b22
--- /dev/null
+++ b/agents/crawler/config/targets.schema.json
@@ -0,0 +1,224 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://mega-directory.dev/schemas/crawler-targets.json",
+  "title": "Mega Directory Crawler Configuration",
+  "type": "object",
+  "description": "Schema describing crawler API targets, scraping targets, and optional LLM field generation rules.",
+  "additionalProperties": true,
+  "properties": {
+    "$schema": {
+      "type": "string",
+      "description": "Optional pointer for tooling to locate this schema definition."
+    },
+    "api_endpoint": {
+      "type": "string",
+      "format": "uri",
+      "description": "Single API endpoint to POST crawler batches to when api_targets is omitted."
+    },
+    "api_token": {
+      "$ref": "#/$defs/nonEmptyString",
+      "description": "Bearer token paired with api_endpoint."
+    },
+    "api_request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) when posting batches to the API."
+    },
+    "request_timeout": {
+      "$ref": "#/$defs/positiveNumber",
+      "description": "Override timeout (seconds) for crawling requests."
+    },
+    "api_targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/apiTarget"
+      },
+      "description": "Optional list of named API targets (e.g., dev and prod)."
+    },
+    "targets": {
+      "type": "array",
+      "minItems": 1,
+      "items": {
+        "$ref": "#/$defs/target"
+      },
+      "description": "Collection of category/location scraping targets."
+    }
+  },
+  "required": ["targets"],
+  "allOf": [
+    {
+      "anyOf": [
+        { "required": ["api_targets"] },
+        { "required": ["api_endpoint", "api_token"] }
+      ]
+    }
+  ],
+  "$defs": {
+    "nonEmptyString": {
+      "type": "string",
+      "minLength": 1
+    },
+    "positiveInteger": {
+      "type": "integer",
+      "minimum": 1
+    },
+    "positiveNumber": {
+      "type": "number",
+      "exclusiveMinimum": 0
+    },
+    "stringList": {
+      "type": "array",
+      "items": {
+        "$ref": "#/$defs/nonEmptyString"
+      },
+      "minItems": 1
+    },
+    "apiTarget": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "endpoint": {
+          "type": "string",
+          "format": "uri"
+        },
+        "token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "api_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "bearer_token": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        }
+      },
+      "required": ["endpoint"],
+      "allOf": [
+        {
+          "anyOf": [
+            { "required": ["token"] },
+            { "required": ["api_token"] },
+            { "required": ["bearer_token"] }
+          ]
+        }
+      ]
+    },
+    "target": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "category": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "category_slug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "categorySlug": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "locations": {
+          "$ref": "#/$defs/stringList"
+        },
+        "keywords": {
+          "$ref": "#/$defs/stringList"
+        },
+        "subdomain": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "search_url_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "selectors": {
+          "$ref": "#/$defs/selectors"
+        },
+        "fields": {
+          "$ref": "#/$defs/fieldMap"
+        },
+        "listings_per_location": {
+          "$ref": "#/$defs/positiveInteger"
+        },
+        "request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "api_request_timeout": {
+          "$ref": "#/$defs/positiveNumber"
+        },
+        "source_name": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "sourceName": {
+          "$ref": "#/$defs/nonEmptyString"
+        }
+      },
+      "required": ["category", "locations"]
+    },
+    "selectors": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "listing": { "$ref": "#/$defs/nonEmptyString" },
+        "title": { "$ref": "#/$defs/nonEmptyString" },
+        "link": { "$ref": "#/$defs/nonEmptyString" },
+        "description": { "$ref": "#/$defs/nonEmptyString" }
+      }
+    },
+    "fieldMap": {
+      "type": "object",
+      "minProperties": 1,
+      "patternProperties": {
+        ".+": {
+          "$ref": "#/$defs/fieldConfig"
+        }
+      }
+    },
+    "fieldConfig": {
+      "type": "object",
+      "additionalProperties": true,
+      "properties": {
+        "source": {
+          "type": "string",
+          "enum": ["scrape", "ai"],
+          "default": "scrape"
+        },
+        "attribute": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "provider": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "model": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "prompt_template": {
+          "$ref": "#/$defs/nonEmptyString"
+        },
+        "options": {
+          "type": "object"
+        },
+        "tokens": {
+          "type": "object",
+          "additionalProperties": {
+            "type": "string"
+          }
+        }
+      },
+      "allOf": [
+        {
+          "if": {
+            "properties": {
+              "source": { "const": "ai" }
+            }
+          },
+          "then": {
+            "required": ["provider", "model", "prompt_template"]
+          }
+        }
+      ]
+    }
+  }
+}
diff --git a/agents/crawler/targets.example.json b/agents/crawler/targets.example.json
index b98ae37a56591370df6217ab8d504fdab790d5a8..5a86e14dad84b94efd1ed95335161deb8cef0eb7
--- a/agents/crawler/targets.example.json
+++ b/agents/crawler/targets.example.json
@@ -1,4 +1,5 @@
 {
+  "$schema": "./config/targets.schema.json",
   "api_targets": [
     {
       "name": "dev",
diff --git a/agents/crawler/tests/test_config_schema.py b/agents/crawler/tests/test_config_schema.py
new file mode 100644
index 0000000000000000000000000000000000000000..81825ce6bd0ac4c04fe4f7c55f6bfc5c2984b4b4
--- /dev/null
+++ b/agents/crawler/tests/test_config_schema.py
@@ -0,0 +1,65 @@
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import jsonschema
+import pytest
+
+
+AGENT_DIR = Path(__file__).resolve().parents[1]
+SCHEMA_PATH = AGENT_DIR / "config" / "targets.schema.json"
+EXAMPLE_PATH = AGENT_DIR / "targets.example.json"
+
+
+@pytest.fixture(scope="module")
+def schema() -> dict:
+    """Load the crawler configuration schema once per test module."""
+    with SCHEMA_PATH.open("r", encoding="utf-8") as fp:
+        return json.load(fp)
+
+
+def _collect_errors(schema: dict, instance: dict) -> list[jsonschema.ValidationError]:
+    validator = jsonschema.Draft202012Validator(schema)
+    return sorted(validator.iter_errors(instance), key=lambda err: list(err.path))
+
+
+def test_example_config_matches_schema(schema: dict) -> None:
+    with EXAMPLE_PATH.open("r", encoding="utf-8") as fp:
+        config = json.load(fp)
+
+    errors = _collect_errors(schema, config)
+
+    assert not errors, f"example config failed schema validation: {[e.message for e in errors]}"
+
+
+def test_schema_rejects_targets_missing_required_fields(schema: dict) -> None:
+    invalid_config = {
+        "api_targets": [
+            {
+                "name": "dev",
+                "endpoint": "https://dev.example.com/v1/crawler/listings",
+                "token": "token",
+            }
+        ],
+        "targets": [
+            {
+                # Missing category and locations entries to trigger schema errors
+                "fields": {
+                    "description": {
+                        "source": "ai",
+                        "model": "gpt-4",
+                        "prompt_template": "Describe {{ listing.title }}",
+                    }
+                },
+            }
+        ],
+    }
+
+    errors = _collect_errors(schema, invalid_config)
+
+    messages = "\n".join(error.message for error in errors)
+    assert errors, "expected schema to flag invalid target configuration"
+    assert "'category'" in messages
+    assert "'locations'" in messages or "minItems" in messages
+    assert "'provider'" in messages

tokens used
61,168
**Updates**
- Added a comprehensive JSON Schema that captures crawler-level API settings, per-target selectors, keyword lists, and conditional AI field requirements so configs can be validated consistently (agents/crawler/config/targets.schema.json:1).
- Linked both the example and active crawler configurations to the new schema via `$schema` pointers, enabling editor tooling and keeping the files self-describing (agents/crawler/targets.example.json:2, agents/crawler/config/targets.json:2).
- Introduced Pytest coverage to load the schema, ensure the example config passes, and confirm that malformed targets (missing category/locations or AI parameters) are rejected, giving us a regression harness for future schema tweaks (agents/crawler/tests/test_config_schema.py:1).

**Tests**
- `cd agents/crawler && pytest`

**Next**
1. Consider calling the schema validator before running the crawler so invalid configs are caught with a clear error message instead of failing mid-run.
